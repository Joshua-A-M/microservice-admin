2025-08-17 20:24:36 [background-preinit] INFO  [,] org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
2025-08-17 20:24:36 [restartedMain] INFO  [,] com.chatservice.admin.EmployeeserviceApplication - Starting EmployeeserviceApplication using Java 21.0.7 with PID 15968 (C:\Users\Joshu\DevDirectory\JavaEnv\Microservices\ChatService\admin\build\classes\java\main started by Joshu in C:\Users\Joshu\DevDirectory\JavaEnv\Microservices\ChatService\admin)
2025-08-17 20:24:36 [restartedMain] INFO  [,] com.chatservice.admin.EmployeeserviceApplication - No active profile set, falling back to 1 default profile: "default"
2025-08-17 20:24:36 [restartedMain] INFO  [,] org.springframework.boot.devtools.env.DevToolsPropertyDefaultsPostProcessor - Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2025-08-17 20:24:36 [restartedMain] INFO  [,] org.springframework.boot.devtools.env.DevToolsPropertyDefaultsPostProcessor - For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2025-08-17 20:24:37 [restartedMain] INFO  [,] org.springframework.data.repository.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-08-17 20:24:37 [restartedMain] INFO  [,] org.springframework.data.repository.config.RepositoryConfigurationDelegate - Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2025-08-17 20:24:37 [restartedMain] INFO  [,] org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport - Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.chatservice.admin.repository.MemberRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
2025-08-17 20:24:37 [restartedMain] INFO  [,] org.springframework.data.repository.config.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 154 ms. Found 1 Redis repository interface.
2025-08-17 20:24:37 [restartedMain] INFO  [,] org.springframework.data.repository.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-08-17 20:24:37 [restartedMain] INFO  [,] org.springframework.data.repository.config.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFAULT mode.
2025-08-17 20:24:38 [restartedMain] INFO  [,] org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface com.chatservice.admin.repository.UserRedisRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
2025-08-17 20:24:38 [restartedMain] INFO  [,] org.springframework.data.repository.config.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 37 ms. Found 1 JPA repository interface.
2025-08-17 20:24:38 [restartedMain] INFO  [,] org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor - No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2025-08-17 20:24:38 [restartedMain] INFO  [,] org.springframework.integration.config.DefaultConfiguringBeanFactoryPostProcessor - No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2025-08-17 20:24:38 [restartedMain] INFO  [,] org.springframework.cloud.context.scope.GenericScope - BeanFactory id=02172468-6815-32b7-873c-affa00df986d
2025-08-17 20:24:39 [restartedMain] INFO  [,] org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat initialized with port 8080 (http)
2025-08-17 20:24:39 [restartedMain] INFO  [,] org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8080"]
2025-08-17 20:24:39 [restartedMain] INFO  [,] org.apache.catalina.core.StandardService - Starting service [Tomcat]
2025-08-17 20:24:39 [restartedMain] INFO  [,] org.apache.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.42]
2025-08-17 20:24:39 [restartedMain] INFO  [,] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
2025-08-17 20:24:39 [restartedMain] INFO  [,] org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 2901 ms
2025-08-17 20:24:39 [restartedMain] INFO  [,] org.hibernate.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-08-17 20:24:39 [restartedMain] INFO  [,] org.hibernate.Version - HHH000412: Hibernate ORM core version 6.6.18.Final
2025-08-17 20:24:39 [restartedMain] INFO  [,] org.hibernate.cache.internal.RegionFactoryInitiator - HHH000026: Second-level cache disabled
2025-08-17 20:24:40 [restartedMain] INFO  [,] org.springframework.orm.jpa.persistenceunit.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-08-17 20:24:40 [restartedMain] INFO  [,] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
2025-08-17 20:24:40 [restartedMain] INFO  [,] com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Added connection org.postgresql.jdbc.PgConnection@18443ef9
2025-08-17 20:24:40 [restartedMain] INFO  [,] com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
2025-08-17 20:24:40 [restartedMain] INFO  [,] org.hibernate.orm.connections.pooling - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (HikariPool-1)']
	Database driver: undefined/unknown
	Database version: 17.5
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-08-17 20:24:41 [restartedMain] INFO  [,] org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-08-17 20:24:41 [restartedMain] INFO  [,] org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-08-17 20:24:42 [restartedMain] INFO  [,] org.springframework.data.jpa.repository.query.QueryEnhancerFactory - Hibernate is in classpath; If applicable, HQL parser will be used.
2025-08-17 20:24:42 [restartedMain] WARN  [,] org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer - Unable to start LiveReload server
2025-08-17 20:24:43 [restartedMain] WARN  [,] org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration - spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
2025-08-17 20:24:43 [restartedMain] INFO  [,] org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration - Eureka HTTP Client uses RestTemplate.
2025-08-17 20:24:44 [restartedMain] WARN  [,] org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger - Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2025-08-17 20:24:44 [restartedMain] WARN  [,] org.springframework.cloud.function.context.catalog.BeanFactoryAwareFunctionRegistry - Failed to locate function 'userTopicSubscriber' for function definition 'userTopicSubscriber'. Returning null.
2025-08-17 20:24:44 [restartedMain] INFO  [,] org.springframework.cloud.stream.messaging.DirectWithAttributesChannel - Channel 'employeeservice.userTopicSubscriber-in-0' has 1 subscriber(s).
2025-08-17 20:24:44 [restartedMain] INFO  [,] org.springframework.integration.endpoint.EventDrivenConsumer - Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2025-08-17 20:24:44 [restartedMain] INFO  [,] org.springframework.integration.channel.PublishSubscribeChannel - Channel 'employeeservice.errorChannel' has 1 subscriber(s).
2025-08-17 20:24:44 [restartedMain] INFO  [,] org.springframework.integration.endpoint.EventDrivenConsumer - started bean '_org.springframework.integration.errorLogger'
2025-08-17 20:24:44 [restartedMain] INFO  [,] org.springframework.cloud.netflix.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
2025-08-17 20:24:44 [restartedMain] INFO  [,] com.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
2025-08-17 20:24:44 [restartedMain] INFO  [,] com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
2025-08-17 20:24:44 [restartedMain] INFO  [,] com.netflix.discovery.DiscoveryClient - Disable delta property : false
2025-08-17 20:24:44 [restartedMain] INFO  [,] com.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
2025-08-17 20:24:44 [restartedMain] INFO  [,] com.netflix.discovery.DiscoveryClient - Force full registry fetch : false
2025-08-17 20:24:44 [restartedMain] INFO  [,] com.netflix.discovery.DiscoveryClient - Application is null : false
2025-08-17 20:24:44 [restartedMain] INFO  [,] com.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
2025-08-17 20:24:44 [restartedMain] INFO  [,] com.netflix.discovery.DiscoveryClient - Application version is -1: true
2025-08-17 20:24:44 [restartedMain] INFO  [,] com.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
2025-08-17 20:24:44 [restartedMain] INFO  [,] com.netflix.discovery.DiscoveryClient - The response status is 200
2025-08-17 20:24:44 [restartedMain] INFO  [,] com.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
2025-08-17 20:24:44 [restartedMain] INFO  [,] com.netflix.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
2025-08-17 20:24:44 [restartedMain] INFO  [,] com.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1755487484877 with initial instances count: 4
2025-08-17 20:24:44 [restartedMain] INFO  [,] org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry - Registering application EMPLOYEESERVICE with eureka with status UP
2025-08-17 20:24:44 [restartedMain] INFO  [,] com.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1755487484885, current=UP, previous=STARTING]
2025-08-17 20:24:44 [DiscoveryClient-InstanceInfoReplicator-%d] INFO  [,] com.netflix.discovery.DiscoveryClient - DiscoveryClient_EMPLOYEESERVICE/Base:employeeservice: registering service...
2025-08-17 20:24:44 [restartedMain] INFO  [,] org.springframework.cloud.stream.binder.DefaultBinderFactory - Creating binder: kafka
2025-08-17 20:24:44 [restartedMain] INFO  [,] org.springframework.cloud.stream.binder.DefaultBinderFactory - Constructing binder child context for kafka
2025-08-17 20:24:44 [DiscoveryClient-InstanceInfoReplicator-%d] INFO  [,] com.netflix.discovery.DiscoveryClient - DiscoveryClient_EMPLOYEESERVICE/Base:employeeservice - registration status: 204
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.springframework.cloud.stream.binder.DefaultBinderFactory - Caching the binder: kafka
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1755487485201
2025-08-17 20:24:45 [kafka-admin-client-thread | adminclient-1] INFO  [,] org.apache.kafka.common.utils.AppInfoParser - App info kafka.admin.client for adminclient-1 unregistered
2025-08-17 20:24:45 [kafka-admin-client-thread | adminclient-1] INFO  [,] org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-08-17 20:24:45 [kafka-admin-client-thread | adminclient-1] INFO  [,] org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-08-17 20:24:45 [kafka-admin-client-thread | adminclient-1] INFO  [,] org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector - initializing Kafka metrics collector
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1755487485955
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-1, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] Cluster ID: uuidgen
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-1, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-1, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] Request joining group due to: consumer pro-actively leaving the group
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
2025-08-17 20:24:45 [restartedMain] INFO  [,] org.apache.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-1 unregistered
2025-08-17 20:24:46 [restartedMain] INFO  [,] org.springframework.cloud.stream.binder.BinderErrorChannel - Channel 'kafka-457293488.userTopicSubscriber-in-0.errors' has 1 subscriber(s).
2025-08-17 20:24:46 [restartedMain] INFO  [,] org.springframework.cloud.stream.binder.BinderErrorChannel - Channel 'kafka-457293488.userTopicSubscriber-in-0.errors' has 0 subscriber(s).
2025-08-17 20:24:46 [restartedMain] INFO  [,] org.springframework.cloud.stream.binder.BinderErrorChannel - Channel 'kafka-457293488.userTopicSubscriber-in-0.errors' has 1 subscriber(s).
2025-08-17 20:24:46 [restartedMain] INFO  [,] org.springframework.cloud.stream.binder.BinderErrorChannel - Channel 'kafka-457293488.userTopicSubscriber-in-0.errors' has 2 subscriber(s).
2025-08-17 20:24:46 [restartedMain] INFO  [,] org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-08-17 20:24:46 [restartedMain] INFO  [,] org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector - initializing Kafka metrics collector
2025-08-17 20:24:46 [restartedMain] INFO  [,] org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-08-17 20:24:46 [restartedMain] INFO  [,] org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-08-17 20:24:46 [restartedMain] INFO  [,] org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1755487486039
2025-08-17 20:24:46 [restartedMain] INFO  [,] org.apache.kafka.clients.consumer.internals.ClassicKafkaConsumer - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] Subscribed to topic(s): user-change-topic
2025-08-17 20:24:46 [restartedMain] INFO  [,] org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter - started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@12a9b67a
2025-08-17 20:24:46 [restartedMain] INFO  [,] org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8080"]
2025-08-17 20:24:46 [KafkaConsumerDestination{consumerDestinationName='user-change-topic', partitions=1, dlqName='null'}.container-0-C-1] INFO  [,] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] Cluster ID: uuidgen
2025-08-17 20:24:46 [KafkaConsumerDestination{consumerDestinationName='user-change-topic', partitions=1, dlqName='null'}.container-0-C-1] INFO  [,] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null)
2025-08-17 20:24:46 [KafkaConsumerDestination{consumerDestinationName='user-change-topic', partitions=1, dlqName='null'}.container-0-C-1] INFO  [,] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] (Re-)joining group
2025-08-17 20:24:46 [restartedMain] INFO  [,] org.springframework.boot.web.embedded.tomcat.TomcatWebServer - Tomcat started on port 8080 (http) with context path '/'
2025-08-17 20:24:46 [restartedMain] INFO  [,] org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration - Updating port to 8080
2025-08-17 20:24:46 [KafkaConsumerDestination{consumerDestinationName='user-change-topic', partitions=1, dlqName='null'}.container-0-C-1] INFO  [,] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] Request joining group due to: need to re-join with the given member-id: consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2-eadd78ec-6f33-4081-b5d2-c7c61b29dc79
2025-08-17 20:24:46 [KafkaConsumerDestination{consumerDestinationName='user-change-topic', partitions=1, dlqName='null'}.container-0-C-1] INFO  [,] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] (Re-)joining group
2025-08-17 20:24:46 [restartedMain] INFO  [,] com.chatservice.admin.EmployeeserviceApplication - Started EmployeeserviceApplication in 10.438 seconds (process running for 11.58)
2025-08-17 20:24:46 [restartedMain] INFO  [,] com.chatservice.admin.EmployeeserviceApplication - 
Application started — JSON logging enabled!
2025-08-17 20:24:49 [KafkaConsumerDestination{consumerDestinationName='user-change-topic', partitions=1, dlqName='null'}.container-0-C-1] INFO  [,] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2-eadd78ec-6f33-4081-b5d2-c7c61b29dc79', protocol='range'}
2025-08-17 20:24:49 [KafkaConsumerDestination{consumerDestinationName='user-change-topic', partitions=1, dlqName='null'}.container-0-C-1] INFO  [,] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] Finished assignment for group at generation 1: {consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2-eadd78ec-6f33-4081-b5d2-c7c61b29dc79=Assignment(partitions=[user-change-topic-0])}
2025-08-17 20:24:49 [KafkaConsumerDestination{consumerDestinationName='user-change-topic', partitions=1, dlqName='null'}.container-0-C-1] INFO  [,] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2-eadd78ec-6f33-4081-b5d2-c7c61b29dc79', protocol='range'}
2025-08-17 20:24:49 [KafkaConsumerDestination{consumerDestinationName='user-change-topic', partitions=1, dlqName='null'}.container-0-C-1] INFO  [,] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] Notifying assignor about the new Assignment(partitions=[user-change-topic-0])
2025-08-17 20:24:49 [KafkaConsumerDestination{consumerDestinationName='user-change-topic', partitions=1, dlqName='null'}.container-0-C-1] INFO  [,] org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] Adding newly assigned partitions: user-change-topic-0
2025-08-17 20:24:49 [KafkaConsumerDestination{consumerDestinationName='user-change-topic', partitions=1, dlqName='null'}.container-0-C-1] INFO  [,] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] Found no committed offset for partition user-change-topic-0
2025-08-17 20:24:49 [KafkaConsumerDestination{consumerDestinationName='user-change-topic', partitions=1, dlqName='null'}.container-0-C-1] INFO  [,] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] Found no committed offset for partition user-change-topic-0
2025-08-17 20:24:49 [KafkaConsumerDestination{consumerDestinationName='user-change-topic', partitions=1, dlqName='null'}.container-0-C-1] INFO  [,] org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4-2, groupId=anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4] Resetting offset for partition user-change-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=24}}.
2025-08-17 20:24:49 [KafkaConsumerDestination{consumerDestinationName='user-change-topic', partitions=1, dlqName='null'}.container-0-C-1] INFO  [,] org.springframework.cloud.stream.binder.kafka.KafkaMessageChannelBinder$2 - anonymous.68d3a519-8ca2-40a0-8e60-39c0735ecdb4: partitions assigned: [user-change-topic-0]
